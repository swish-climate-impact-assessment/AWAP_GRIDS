#+TITLE:AWAP GRIDS 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* TODOlist
** TODO check solar radiation solarave_2001050820010508.grid
# file.remove('data2000-2004/solar/solarave_2001050820010508.grid')
* Introduction
NCEPH holds Australian Bureau of Meteorology data for all stations from 1990 to 2010 \cite{NationalClimateCentreoftheBureauofMeteorology:2005}.
The aim of this project is to download the Australian Water Availability Project (AWAP) gridded datasets \cite{Jones2009}.  In particular we want the vapour pressure data from 2010 so that we don't have to buy it again.  We want to compare it with the station data to see if they are close.
* The Codes
** plan
#+begin_src R :session *R* :tangle no :exports none :eval no
  if(!require(devtools)) install.packages("devtools", repos = 'http://cran.csiro.au'); require(devtools)
  if(!require(disentangle)) install_github("disentangle", "ivanhanigan"); require(disentangle)
  
  nodes <- newnode(name='main.r', newgraph = T,
   inputs = 'init')
  
  nodes <- newnode(name='zones',
   inputs='main.r')
  
#+end_src
** init

#+name: R-init
#+begin_src R  :session *R* :exports none :eval no :tangle no
  # INITIALISE THE PROJECT
  if (!require(ProjectTemplate)) install.packages('ProjectTemplate', repos='http://cran.csiro.au'); require(ProjectTemplate)
  if (!require(makeProject)) install.packages('makeProject', repos='http://cran.csiro.au'); require(makeProject)
  setwd('..')
  dir()
  create.project('AWAP2')
  #copy into curr dir
  ?makeProject
  makeProject(author='ivanhanigan',email='ivan.hanigan@gmail.com',force=TRUE, name = "AWAP_GRIDS")
  
  
  setwd('AWAP_GRIDS')
  load.project()
  
  
  
  
#+end_src
** config
#+name:global.dcf
#+begin_src R :session *R* :tangle config/global.dcf :exports none :eval no
data_loading: off
cache_loading: on
munging: on
logging: off
load_libraries: on
libraries: reshape, plyr, ggplot2, stringr, lubridate, fgui, raster, rgdal
as_factors: on
data_tables: off

#+end_src

** main
*** main
#+name:main
#+begin_src R :session *R* :tangle main.r :exports none :eval no
  ################################################################
  # Project: AWAP_GRIDS
  # Author: ivanhanigan
  # Maintainer: Who to complain to <ivan.hanigan@gmail.com>
  
  # This is the main file for the project
  # It should do very little except call the other files
  
  ####################
  ### Set the working directory
  if(exists('workdir')){
    workdir <- workdir
  } else {
    workdir <- "~/data/AWAP_GRIDS"
  }
  setwd(workdir)
  
  ####################
  # Functions for the project
  
  if (!require(ProjectTemplate)) install.packages('ProjectTemplate', repos='http://cran.csiro.au'); require(ProjectTemplate)
  load.project()
  
  ####################
  # user definitions, or setup interactively
  startdate <- '2009-08-06'
  enddate <-  '2009-12-31' #Sys.Date()-2
  interactively <- FALSE
  variablenames <- 'maxave,minave,solarave,totals,vprph09,vprph15'
  aggregation_factor <- 3
  os <- 'linux' # only linux and windoze supported
  pgisutils <- "" #"/usr/pgsql-9.1/bin/"
  #"\"C:\\pgutils\\postgis-pg92-binaries-2.0.2w64\\bin\\"
  pgutils <- "\"C:\\pgutils\\pgsql\\bin\\"
  
  ####################
  # run the project (alternately do this from Kepler)
  source(file.path(workdir, "src/scoping.r"))
  source(file.path(workdir, "src/load.r"))
  # source("src/load.r")
  # source("src/clean.r")
  # source("src/do.r")
  
#+end_src
*** deprecated main
#+name:main-newnode
#+begin_src R :session *R* :tangle no :exports none :eval no
  # Project: AWAP_GRIDS
  # Author: ivanhanigan
  # Maintainer: Who to complain to <ivan.hanigan@gmail.com>
  
  # This is the main file for the project
  # It should do very little except call the other files
  
  ### Set the working directory
  setwd("/home/ivan/data/AWAP_GRIDS")
  
  
  ### Set any global variables here
  if(exists('startdate')){
    startdate <- startdate
  } else {
    startdate <- '2000-01-01'
  }
  if(exists('enddate')){
    enddate <- enddate
  } else {
    enddate <- '2000-01-02'
  }
  
  ####################
  ## if (!require(ProjectTemplate)) install.packages('ProjectTemplate', repos='http://cran.csiro.au'); require(ProjectTemplate)
  ## load.project()
  ## #require(fgui)
  if(!require(fgui)) install.packages("fgui", repos='http://cran.csiro.au'); require(fgui)
  if(!require(swishdbtools)) print('Please download the swishdbtools package and install it.')
  # for instance
  # install.packages("~/tools/swishdbtools_1.0_R_x86_64-pc-linux-gnu.tar.gz", repos = NULL, type = "source");
  require(swishdbtools)
  
  ####################
  getscope <- function (
    sdate = startdate,
    edate = enddate,
    variablenames) {
    scope <- list(
      startdate <- sdate,
      enddate <- edate,
      variablenames <- variablenames
    )
    return(scope)
  }
  scope <- guiv(getscope, argList = list(variablenames = c('totals','maxave','minave','vprph09','vprph15','solarave')))
  # print(scope)
  p <- getPassword()
  
  ####################
  
  # source("src/load.r")
  # source("src/clean.r")
  # source("src/do.r")
  
  
  ### Run the code
  ## source("code/load.R")
  ## source("code/clean.R")
  ## source("code/func.R")
  ## source("code/do.R")
  
#+end_src

** scoping  
#+name:scoping
#+begin_src R :session *shell* :tangle src/scoping.r :exports none :eval no
  ###########################################################################
  # newnode: scoping
  
    require(fgui)
    #require(ProjectTemplate)
    #load.project()
    # # user definitions, or setup interactively
    # startdate <- '1995-01-01'
    # enddate <-  '1997-01-01'
    # interactively <- FALSE
    # variablenames <- 'maxave'
    aggregation_factor <- 3
    # this will aggregate the 5 km pixels into 15 km averages, for storage
    if (exists('startdate')){
      startdate <- as.Date(startdate)
    } else {
      startdate <- '2013-01-08'
    }
    if (exists('enddate')){
      enddate <- as.Date(enddate)
    } else {
      enddate <-  '2013-01-20'
    }
    if (exists('interactively')){
      interactively <- interactively
    } else {
      interactively <- FALSE
    }
    # if (variablenames == 'all'){
    # variablenames <-  c('totals','maxave','minave','vprph09','vprph15','solarave'))
    # }
    if (exists('variablenames')){
      variablenames <- variablenames
      variablenames <- strsplit(variablenames, ',')
    } else {
      variablenames <- 'maxave,minave,totals'
      variablenames <- strsplit(variablenames, ',')
    }
    # if these all exist don't run the scope gui?
    #if(!exists('username') & !exists('spatialzones') & !exists('outdir')){
    # or set
  
    if(interactively == TRUE){
      getscope <- function (
        sdate = startdate,
        edate = enddate,
        variablenames) {
        scope <- list(
          startdate <- sdate,
          enddate <- edate,
          variablenames <- variablenames
        )
        return(scope)
      }
      scope <- guiv(getscope, argList = list(variablenames = c('totals','maxave','minave','vprph09','vprph15','solarave')))
  
    } else {
        scope <- list(
          startdate <- startdate,
          enddate <- enddate,
          variablenames <- variablenames
        )
    }
    print(scope)
  
#+end_src
*** deprecated scoping
#+name:scope
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:scope
# This workflow will deliver weather data from the EWEDB to a local directory.
# Ivan Hanigan 2012-12-14

# README:
#   Running this workflow will cause a GUI box to appear for your password.
# Sometimes this GUI box is behind other windows.
# 
# Either change the inputs above, or set interactively to TRUE.
# In interactively mode a GUI box will open where you can change the values, 
# or leave blank to accept the defaults.
# 
# NB dates need quotation marks if using the GUI box.
# 
# TODO:
#   There are missing days in  solarave, vprph09, vprph15.
# Try downloading again to see if fixed now.
# Add the population weighted averaging approach.

if(!require(fgui)) install.packages("fgui", repos='http://cran.csiro.au'); require(fgui)
if(!require(swishdbtools)) print('Please download the swishdbtools package and install it.')
# for instance 
# install.packages("~/tools/swishdbtools_1.0_R_x86_64-pc-linux-gnu.tar.gz", repos = NULL, type = "source");
require(swishdbtools)


# # user definitions, or setup interactively
# username <- 'gislibrary'
# spatialzones <- 'SD'
# outdir <- '~/'
# startdate <- '1995-01-01'
# enddate <-  '1997-01-01'
# interactively <- TRUE 
# 
if (exists('username')) {
  u <- username
} else {
  u <- 'gislibrary'
}
if (exists('spatialzones')) {
  s <- spatialzones
} else {
  s <- 'SD'
}
if (exists('outdir')) {
  o <- outdir
} else {
  o <- '~/'
}
if (exists('startdate')){
  startdate <- as.Date(startdate) 
} else {
  startdate <- '1995-01-01'
}
if (exists('enddate')){    
  enddate <- as.Date(enddate)
} else {
  enddate <-  '1997-01-01'
}
if (exists('interactively')){    
  interactively <- interactively
} else {
  interactively <- TRUE
}
# if these all exist don't run the scope gui?
#if(!exists('username') & !exists('spatialzones') & !exists('outdir')){
# or set 

if(interactively == TRUE){
  scope <- function(usernameOrBlank=u, 
                    spatialzonesOrBlank = s, 
                    outdirOrBlank=o,
                    startdateOrBlank=startdate,
                    enddateOrBlank=enddate){
    L <- list(
      u <- usernameOrBlank,
      s <- spatialzonesOrBlank,
      o <- outdirOrBlank,
      startdate <- startdateOrBlank,
      enddate <- enddateOrBlank
    )
    return(L)
  }
  Listed <- guiv(scope)
  Listed
  u <- Listed[1]
  s <- Listed[2]
  o <- Listed[[3]][1]
  startdate <- as.Date(Listed[[4]][1])
  enddate <- as.Date(Listed[[5]][1])
}
# don't let password get hardcoded
p <- getPassword()

# ch <- connect2postgres(h = '115.146.84.135', 
#                        d =  'ewedb', 
#                        u = u, 
#                        p = p)


# dat <- dbGetQuery(ch,
#                  "SELECT date, year, sla_code, minave, maxave, solarave, vprph09,vprph15
#                  FROM weather_sla.weather_sla
#                  where sla_code = 105051100 order by date
# ")
# with(dat, plot(date, maxave, type = 'l'))

#+end_src




** func
*** core libs
#+begin_src R  :session *R* :exports none :eval no :tangle lib/func.r
  # Project: AWAP_GRIDS
  # Author: ivanhanigan
  # Maintainer: Who to complain to <ivan.hanigan@gmail.com>
  
  # Functions for the project
  if (!require(plyr)) install.packages('plyr', repos='http://cran.csiro.au'); require(plyr)
  if(!require(swishdbtools)){
  print('Downloading the swishdbtools package and install it.')
  download.file('http://swish-climate-impact-assessment.github.com/tools/swishdbtools/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz', '~/tools/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz', mode = 'wb')
  # for instance
  install.packages("~/tools/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz", repos = NULL, type = "source");
  }
  require(swishdbtools)
  if(!require(raster)) install.packages('raster', repos='http://cran.csiro.au');require(raster)
  if(!require(fgui)) install.packages('fgui', repos='http://cran.csiro.au');require(fgui)
  
  ####
  # MAKE SURE YOU HAVE THE CORE LIBS
  if (!require(lubridate)) install.packages('lubridate', repos='http://cran.csiro.au'); require(lubridate)
  if (!require(reshape)) install.packages('reshape', repos='http://cran.csiro.au'); require(reshape)
  if (!require(plyr)) install.packages('plyr', repos='http://cran.csiro.au'); require(plyr)
  if (!require(ggplot2)) install.packages('ggplot2', repos='http://cran.csiro.au'); require(ggplot2)
  
#+end_src
*** Get Data Range
#+begin_src R :session *R* :tangle lib/get_data_range.r :exports none :eval no
# newnode get_data
# authors: Joseph Guillaume and Francis Markham
# downloads from http://www.bom.gov.au/jsp/awap/
get_data<-function(variable,measure,timestep,startdate,enddate){
  url="http://www.bom.gov.au/web03/ncc/www/awap/{variable}/{measure}/{timestep}/grid/0.05/history/nat/{startdate}{enddate}.grid.Z"
  url=gsub("{variable}",variable,url,fixed=TRUE)
  url=gsub("{measure}",measure,url,fixed=TRUE)
  url=gsub("{timestep}",timestep,url,fixed=TRUE)
  url=gsub("{startdate}",startdate,url,fixed=TRUE)
  url=gsub("{enddate}",enddate,url,fixed=TRUE)
  download.file(url,sprintf("%s_%s%s.grid.Z",measure,startdate,enddate),mode="wb")
  }
  
get_data_range<-function(variable,measure,timestep,startdate,enddate){
  if (timestep == "daily"){
    thisdate<-startdate
    while (thisdate<=enddate){
      get_data(variable,measure,timestep,format(as.POSIXct(thisdate),"%Y%m%d"),format(as.POSIXct(thisdate),"%Y%m%d"))
      thisdate<-thisdate+as.double(as.difftime(1,units="days"),units="secs")
    }
  } else if (timestep == "month"){
    # Make sure that we go from begin of the month
    startdate <- as.POSIXlt(startdate)
    startdate$mday <- 1
    # Find the first and last day of each month overlapping our range
    data.period.start <- seq(as.Date(startdate), as.Date(enddate), by = 'month')
    data.period.end <- as.Date(sapply(data.period.start, FUN=function(x){as.character(seq(x, x + 40, by = 'month')[2] - 1)}))
    # Download them
    for (i in 1:length(data.period.start)){
      get_data(variable,measure,timestep,format(as.POSIXct(data.period.start[i]),"%Y%m%d"),format(as.POSIXct(data.period.end[i]),"%Y%m%d"))
    }
   
} else {
    stop("Unsupported timestep, only 'daily' and 'month' are currently supported")
  }
}
#+end_src

*** variableslist
#+name:variableslist
#+begin_src R :session *R* :tangle lib/variableslist.r :exports none :eval no
  ###########################################################################
  # newnode: variableslist
  variableslist<-"variable,measure,timestep
  rainfall,totals,daily
  temperature,maxave,daily
  temperature,minave,daily
  vprp,vprph09,daily
  vprp,vprph15,daily
  solar,solarave,daily
  ndvi,ndviave,month
  "
  variableslist <- read.csv(textConnection(variableslist))
    
#+end_src

*** pgListTables
#+name:pgListTables
#+begin_src R :session *R* :tangle lib/pgListTables.r :exports none :eval no
  ################################################################
  # name:pgListTables
  pgListTables <- function(conn, schema, pattern = NA)
  {
    tables <- dbGetQuery(conn, 'select   c.relname, nspname
                         FROM pg_catalog.pg_class c
                         LEFT JOIN pg_catalog.pg_namespace n
                         ON n.oid = c.relnamespace
                         where c.relkind IN (\'r\',\'\') ')
    tables <- tables[grep(schema,tables$nspname),]
    if(!is.na(pattern)) tables <- tables[grep(pattern, tables$relname),]
    tables <- tables[order(tables$relname),]
    return(tables)
  }
#+end_src
*** pgListTables-test
#+name:pgListTables-test
#+begin_src R :session *R* :tangle tests/pgListTables-test.r :exports none :eval no
  ################################################################
  # name:pgListTables-test
  require(ProjectTemplate)
  load.project()
  
  require(swishdbtools)
  ch <- connect2postgres(h = '115.146.84.135', db = 'ewedb', user= 'ivan_hanigan')
  tbls <- pgListTables(conn=ch, schema='awap_grids', pattern='maxave')
  tbls$date <- paste(substr(gsub("maxave_","",tbls[,1]),1,4),
          substr(gsub("maxave_","",tbls[,1]),5,6),
          substr(gsub("maxave_","",tbls[,1]),7,8),
          sep="-")
  head(tbls)
  
#+end_src
*** sqlquery_oracle
#+name:sqlquery
#+begin_src R :session *R* :tangle lib/sqlquery.r :exports none :eval no
  ################################################################
  # name:aggregate_postgres
  sqlquery <- function(channel, dimensions, operation,
                       variable, variablename=NA, into, append = FALSE,
                       tablename, where, group_by_dimensions=NA,
                       having=NA,
                       grant = NA, force = FALSE,
                       print = FALSE)
  {
  
    exists <- try(dbGetQuery(channel,
                             paste("select * from",into,"limit 1")))
    if(!force & length(exists) > 0 & append == FALSE)
                             stop("Table exists. Force Drop or Insert Into?")
    if(force & length(exists) > 0) dbGetQuery(channel,
                             paste("drop table ",into))
    if(length(exists) > 0 & append == TRUE)
      {
        sqlquery <- paste("INSERT INTO ",into," (",
                             paste(names(exists), collapse=',', sep='') ,")\n",
                          "select ", dimensions,
                          sep = ""
                          )
      } else {
        sqlquery <- paste("select ", dimensions, sep = "")
      }
    if(!is.na(operation))
    {
    sqlquery <- paste(sqlquery, ", ", operation, "(",variable,") as ",
      ifelse(is.na(variablename), variable,
      variablename), '\n', sep = "")
    }
    if(append == FALSE){
      sqlquery <- paste(sqlquery, "into ", into ,"\n", sep = "")
    }
    sqlquery <- paste(sqlquery, "from ", tablename ,"\n", sep = "")
    if(!is.na(where))
    {
    sqlquery <- paste(sqlquery, "where ", where, "\n", sep = "")
    }
    if(group_by_dimensions == TRUE)
    {
    sqlquery <- paste(sqlquery, "group by ",dimensions, "\n", sep = "")
    }
  #  cat(sqlquery)
  
  
  
    ## sqlquery <-  paste("select ", dimensions,
    ##                ", ",operation,"(",variables,") as ",variables,
    ##                operation, "
    ##                into ", into ,"
    ##                from ",tablename," t1
    ##                group by ",dimensions,
    ##                sep="")
    if(print) {
      cat(sqlquery)
    } else {
      dbSendQuery(channel, sqlquery)
    }
  
  }
#+end_src
*** sqlquery_postgres
#+name:sqlquery
#+begin_src R :session *R* :tangle lib/sqlquery_postgres.r :exports none :eval no
  ################################################################
  # name:aggregate_postgres
  source('lib/pgListTables.r')
  require(swishdbtools)
  ch <- connect2postgres(hostip='115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
      channel = ch
      dimensions = 'stnum, date'
      variable = 'gv'
      variablename = NA
      into_schema = 'public'
      into_table = 'awapmaxave_qc2'
      append = TRUE
      grant = 'public_group'
      print = TRUE
      from_schema = 'public'
      from_table = 'awapmaxave_qc'
      operation = NA
      force = FALSE
      where = "date = '2007-01-01'"
      group_by_dimensions = FALSE
      having = NA
  
  sqlquery_postgres <- function(channel, dimensions, operation,
                       variable, variablename=NA, into, append = FALSE,
                       tablename, where, group_by_dimensions=NA,
                       having=NA,
                       grant = NA, force = FALSE,
                       print = FALSE)
  {
    # assume ch exists
    exists <- pgListTables(channel, into_schema, into_table)
    if(!force & nrow(exists) > 0 & append == FALSE)
      {
        stop("Table exists. Force Drop or Insert Into?")
      }
  
    if(force & nrow(exists) > 0)
      {
        dbGetQuery(channel, paste("drop table ",into_schema,".",into_table,sep=""))
      } else {
        existing_table <- dbGetQuery(channel,
                                     paste('select * from ',
                                           into_schema,'.',
                                           into_table,' limit 1',sep=''
                                           )
                                     )
      }
  
    if(nrow(exists) > 0 & append == TRUE)
      {
        sqlquery <- paste("INSERT INTO ",into_schema,".",into_table," (",
                             paste(names(existing_table), collapse=',', sep='') ,")\n",
                          "select ", dimensions,
                          sep = ""
                          )
      } else {
        sqlquery <- paste("select ", dimensions, "\n", sep = "")
      }
  
    if(!is.na(operation))
      {
        sqlquery <- paste(sqlquery, ", ", operation, "(",variable,") as ",
        ifelse(is.na(variablename), variable,
        variablename), '\n', sep = "")
      }
  
    # this is when append is true but the table doesnt exist yet
    if(nrow(exists) == 0 & append == TRUE)
      {
        sqlquery <- paste(sqlquery, "into ",
                          into_schema,".",into_table,"\n", sep = ""
                          )
      }
  
    # otherwise append is false and the table just needs to be created
    if(append == FALSE)
      {
        sqlquery <- paste(sqlquery, "into ",
                          into_schema,".",into_table,"\n", sep = ""
                          )
      }
  
    sqlquery <- paste(sqlquery, "from ", tablename ,"\n", sep = "")
  
    if(!is.na(where))
      {
        sqlquery <- paste(sqlquery, "where ", where, "\n", sep = "")
      }
  
    if(group_by_dimensions == TRUE)
      {
        sqlquery <- paste(sqlquery, "group by ",
                          dimensions, "\n",
                          sep = ""
                          )
      }
  #  cat(sqlquery)
  
  
  
    ## sqlquery <-  paste("select ", dimensions,
    ##                ", ",operation,"(",variables,") as ",variables,
    ##                operation, "
    ##                into ", into ,"
    ##                from ",tablename," t1
    ##                group by ",dimensions,
    ##                sep="")
    if(print) {
      cat(sqlquery)
    } else {
      dbSendQuery(channel, sqlquery)
    }
  
  }
  
#+end_src
*** sqlquery-test
#+name:sqlquery-test
#+begin_src R :session *R* :tangle tests/sqlquery-test.r :exports none :eval no
  ################################################################
  # name:sqlquery-test
  
  
    require(ProjectTemplate)
    load.project()
  
    require(swishdbtools)
    ch <- connect2postgres(hostip='115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
  
    variable_j <- "maxave"
    date_i <- '2012-01-01'
  #  debug(sqlquery)
    sqlquery(channel = ch,
      dimensions = paste("stnum, cast('",date_i,"' as date) as date",sep=""),
      variable = 'rt.rast, pt.the_geom',
      variablename = 'gv',
      into = 'awapmaxave_qc',
      append = FALSE,
      grant = 'public_group',
      print = FALSE,
      tablename = paste('awap_grids.',variable_j,'_',gsub('-','',date_i),' rt,\n weather_bom.combstats pt',sep=''),
      operation = "ST_Value",
      force = TRUE,
      where = "ST_Intersects(rast, the_geom)",
      group_by_dimensions = FALSE,
      having = NA)
  #  undebug(sqlquery)
  for(date_i in seq(as.Date('2012-01-21'), as.Date('2013-01-20'), 1))
    {
     date_i <- as.Date(date_i, origin = '1970-01-01')
     date_i <- as.character(date_i)
     print(date_i)
  
  #  debug(sqlquery)
    sqlquery(channel = ch,
      dimensions = paste("stnum, cast('",date_i,"' as date) as date",sep=""),
      variable = 'rt.rast, pt.the_geom',
      variablename = 'gv',
      into = 'awapmaxave_qc',
      append = TRUE,
      grant = 'public_group',
      print = FALSE,
      tablename = paste('awap_grids.',variable_j,'_',gsub('-','',date_i),' rt,\n weather_bom.combstats pt',sep=''),
      operation = "ST_Value",
      force = FALSE,
      where = "ST_Intersects(rast, the_geom)",
      group_by_dimensions = FALSE,
      having = NA)
    }
  
#+end_src

** load
*** TODO recognise if day not available
#+name:load
#+begin_src R :session *R* :tangle src/load.r :exports none :eval no
    ################################################################
    # name:load
    # Project: AWAP_GRIDS
    # Author: ivanhanigan
    # Maintainer: Who to complain to <ivan.hanigan@gmail.com>
  
    # This file loads all the libraries and data files needed
    # Don't do any cleanup here
  
    ### Load any needed libraries
    #load(LibraryName)
    require(ProjectTemplate)
    load.project()

    setwd('data')
    rootdir <- getwd()
    start_at <- scope[[1]][1]
    print(start_at)
    end_at <- scope[[2]][1]
    print(end_at)
    for(date_i in seq(as.Date(start_at), as.Date(end_at), 1))
    {
      date_i <- as.Date(date_i, origin = '1970-01-01')
      date_i <- as.character(date_i)
      print(date_i)
    
      sdate <- date_i
      edate <- date_i
      vars <- scope[[3]]
      print(vars)
     
    #  started <- Sys.time()
      for(i in 1:length(vars[[1]])){
  #     i <- 1
    #  variable <- variableslist[which(variableslist$measure == vars[[1]][i]),]
      variable <- variableslist[which(variableslist$measure == vars[[1]][i]),]
      vname <- as.character(variable[,1])
      #try(dir.create(vname))
      #setwd(vname)
      # TODO recognise if day not available to download
      get_data_range(variable=as.character(variable[,1]),measure =as.character(variable[,2]),timestep=as.character(variable[,3]),
                      startdate=as.POSIXct(sdate),
                      enddate=as.POSIXct(edate))
  
      files <- dir(pattern='.grid.Z$')
      if(os == 'linux'){
      for (f in files) {
        # f <- files[1]
        print(f)
        system(sprintf('uncompress %s',f))
      }
      } else {
       for (f in files) {
       if(!require(uncompress)) "find the old uncompress package off cran";
       require(uncompress)
       #f <- files[1]
       print(f)
       handle <- file(f, "rb")
       data <- readBin(handle, "raw", 99999999)
       close(handle)
       uncomp_data <- uncompress(data)
       handle <- file(gsub('.Z','',f), "wb")
       writeBin(uncomp_data, handle)
       close(handle)
       # clean up
       file.remove(f)
       }
      }
      files <- dir(pattern=".grid$")
      for(fname in files){
        # fname <- files[1]
        r <- raster(fname)
    #    writeGDAL(r, gsub('.grid','test1.TIF',fname), drivername="GTiff")
        #r <- raster(r)
        r <- aggregate(r, fact = aggregation_factor, fun = mean)
        writeRaster(r, gsub('.grid','.TIF',fname), format="GTiff",
      overwrite = TRUE)
        file.remove(fname)
      }
      files <- dir(pattern=".tif$")
      for(fname in files){
  #    fname <- files[1]
        outname <- gsub('.tif',"", fname)
        outname <- substr(outname, 1, nchar(outname) - 8)
        if(os == 'linux'){
  
         system(
  #         cat(
             paste(pgisutils,"raster2pgsql -s 4283 -I -C -M ",fname," -F awap_grids.",outname," > ",outname,".sql", sep="")
             )
         system(
           #cat(
           paste("psql -h 115.146.84.135 -U gislibrary -d ewedb -f ",outname,".sql",
                 sep = ""))
       } else {
         sink('raster2sql.bat')
         cat(paste(pgisutils,"raster2pgsql\" -s 4283 -I -C -M ",fname," -F awap_grids.",outname," > ",outname,".sql\n",sep=""))
  
         cat(
         paste(pgutils,"psql\" -h 115.146.84.135 -U gislibrary -d ewedb -f ",outname,".sql", sep = ""))
         sink()
         system('raster2sql.bat')
         file.remove('raster2sql.bat')
       }
      }
      files <- dir()
      # cleanup
      for(fname in files){
        file.remove(fname)
      }
      #setwd('..')
      }
     }
     setwd('..')
  
#+end_src
*** deprecated code
#+name:deprecated code
#+begin_src R :session *shell* :tangle no :exports none :eval no
###########################################################################
# newnode: deprecated code


      #}
  
      ## finished <- Sys.time()
      ## finished - started
      ## system('df -h')
      ## # newnode uncompress
      ## # test with one
      ## started <- Sys.time()
      ## for(i in 1:6){
      ## # i <- 1
      ## variable <- as.character(vars[i,1])
      ## print(variable)
      ## setwd(variable)
      ## files <- dir(pattern='.grid.Z')
      ## # files
      ## for (f in files) {
      ## # f <- files[1]
  
      ## # print(f)
      ## system(sprintf('uncompress %s',f))
      ## # grid2csv(gsub('.Z','',f))
      ## }
      ## setwd(rootdir)
      ## }
      ## finished <- Sys.time()
      ## finished - started
      ## system('df -h')
  
    #  files
    #  alreadyGot <- dir(file.path(workdir,paste('data',year,'-', year2, sep=''), vname), pattern='.grid')
    #  alreadyGot[1:10]
    #  gsub('.Z','',files) %in% alreadyGot
  
#+end_src

*** deprecated load

# don't let password get hardcoded
#p <- getPassword()
  
# ch <- connect2postgres(h = '115.146.84.135',
#                        d =  'ewedb',
#                        u = u,
#                        p = p)
  
  
# dat <- dbGetQuery(ch,
#                  "SELECT date, year, sla_code, minave, maxave, solarave, vprph09,vprph15
#                  FROM weather_sla.weather_sla
#                  where sla_code = 105051100 order by date
# ")
# with(dat, plot(date, maxave, type = 'l'))
  
** test upload to postgres
*** create schema
#+name:create_schema
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:create_schema
CREATE SCHEMA awap_grids
grant ALL on schema awap_grids to ian_szarka;
GRANT ALL ON ALL TABLES IN SCHEMA awap_grids TO ian_szarka;
grant ALL on all functions in schema awap_grids to ian_szarka;
grant ALL on all sequences in schema awap_grids to ian_szarka; 
#+end_src
*** raster2pgsql
http://postgis.refractions.net/docs/using_raster.xml.html#RT_Raster_Loader
ie
raster2pgsql -s 4236 -I -C -M *.tif -F -t 100x100 public.demelevation > elev.sql
psql -d gisdb -f elev.sql
*** SQL extraction
#+name:sql-test
#+begin_src sql :tangle no :exports none :eval no
  
  -- TODO look at diff with ascii grid and geotiff
  -- http://blogs.esri.com/esri/arcgis/2010/12/21/rasters-get-speed-save-space/
  
  -- start with poa
  select poa_code, st_x(the_geom), st_y(the_geom)
  from abs_poa.actpoa01;
  
  select * from awap_grids.tmax2013010820130108 limit 1;
  -- try from postgis tute
  -- http://gis.stackexchange.com/questions/19856/intersecting-a-raster-with-a-polygon-using-postgis-artefact-error/19858#19858
  -- and http://www.mentby.com/Group/postgis-users/extract-a-set-of-wkt-raster-values-from-a-point-geometry-table.html
  CREATE TABLE caribou_srtm_inter AS
   SELECT poa_code, 
          (gv).geom AS the_geom, 
          (gv).val
   FROM (SELECT poa_code, 
                ST_Intersection(rast, the_geom) AS gv
         FROM awap_grids.tmax2013010820130108,
              abs_poa.actpoa01
         WHERE ST_Intersects(rast, the_geom)
        ) foo;
  
   CREATE TABLE result01 AS
   SELECT poa_code, 
          avg(val) AS tmax
   FROM caribou_srtm_inter
   GROUP BY poa_code
   ORDER BY poa_code;
  
   select t1.*,t2.tmax 
   into result02
   from abs_poa.actpoa01 t1
   join
   result01 t2
   on t1.poa_code = t2.poa_code
  
   alter table result02 add column gid2 serial primary key;
  
  -- worked but slow
   -- try NSW
   
  CREATE TABLE caribou_srtm_inter2 AS
   SELECT stnum, 
          (gv).geom AS the_geom, 
          (gv).val
   FROM (SELECT stnum, 
                ST_Intersection(rast, the_geom) AS gv
         FROM awap_grids.tmax2013010820130108,
              weather_bom.combstats
         WHERE ST_Intersects(rast, the_geom)
        ) foo;
  
  select * from caribou_srtm_inter2 limit 1;
  
   select t1.*,t2.tmax 
   into caribou_srtm_inter3
   from weather_bom.combstats t1
   join
   caribou_srtm_inter2 t2
   on t1.stnum = t2.stnum
  
   alter table caribou_srtm_inter3 add column gid2 serial primary key;
  
   -- try2 stations
  
  SELECT stnum,  (gv).val
  into try2
  FROM (
  SELECT pt.stnum, ST_Intersection(rt.rast, pt.the_geom) as gv
  FROM awap_grids.tmax2013010820130108 rt,
              weather_bom.combstats pt
  WHERE ST_Intersects(rast, the_geom)            
  ) foo
   
  --try3
  -- based on http://gis.stackexchange.com/questions/14960/postgis-raster-value-of-a-lat-lon-point
  --drop table try3;
  SELECT pt.stnum, ST_Value(rt.rast, pt.the_geom) as gv
  into try3
  FROM awap_grids.tmax2013010820130108 rt,
              (select * from weather_bom.combstats) pt
  WHERE ST_Intersects(rast, the_geom); 
  select * from try3;
  
  --drop table try3_1;
   select t1.*,t2.gv as tmax 
   into try3_1
   from weather_bom.combstats t1
   join
   try3 t2
   on t1.stnum = t2.stnum;
  
   alter table try3_1 add column gid2 serial primary key;
  
  -- with aggregated pixels
  --drop table try4;
  SELECT pt.stnum, ST_Value(rt.rast, pt.the_geom) as gv
  into try4
  FROM awap_grids.maxave_2013010820130108 rt,
              (select * from weather_bom.combstats) pt
  WHERE ST_Intersects(rast, the_geom); 
  select * from try4;
         
         --drop table try4_1;
          select t1.*,t2.gv as tmax 
   into try4_1
   from weather_bom.combstats t1
   join
   try4 t2
   on t1.stnum = t2.stnum;
  
   alter table try4_1 add column gid2 serial primary key;
  
  -- with bulk upload
  select * from awap_grids.maxave limit 1;
  --drop table try5;
  SELECT pt.stnum, rt.filename, ST_Value(rt.rast, pt.the_geom) as gv
  into try5
  FROM awap_grids.maxave rt,
              (select * from weather_bom.combstats) pt
  WHERE ST_Intersects(rast, the_geom); 
  select * from try5 where stnum = 91004;
  
#+end_src

** test geotiff
save storage space as geotiff
#+name:load
#+begin_src R :session *R* :tangle src/qc-geotiff.r :exports none :eval no
  ################################################################
  # name:test geotiff
  
    rootdir <- paste(getwd(),'/',variableslist[v,1],sep='')
    #  dir(rootdir)[1]
    cfiles <- dir(rootdir)
    cfiles <- cfiles[grep(as.character(variableslist[v,2]), cfiles)]
    fname <- cfiles[[i]]
  
    r <- readGDAL(file.path(rootdir,fname))
    outfile <- gsub('.grid', '.TIF', fname)
    writeGDAL(r, file.path(rootdir, outfile), drivername="GTiff")
    r <- readGDAL(file.path(rootdir,outfile))
  
#+end_src
** test readGDAL
#+name:test-readGDAL
#+begin_src R :session *shell* :tangle no :exports none :eval no
  ################################################################
  # name:test-readGDAL
  require(raster)
  readGDAL2 <- function(hostip=NA,user=NA,db=NA, schema= NA, table=NA, p = NA) {
   if (!require(rgdal)) install.packages('rgdal', repos='http://cran.csiro.au'); require(rgdal)
   if(is.na(p)){
   pwd=readline('enter password (ctrl-L will clear the console after): ')
   } else {
   pwd <- p
   }
   r <- readGDAL(sprintf('PG:host=%s
                           user=%s
                           dbname=%s
                           password=%s
                           table=%s
                           schema=%s
                           port=5432',hostip,user,db,pwd, table, schema)
                          # layer=layer
                 )
   return(r)
  }
  
  r <- readGDAL2('115.146.84.135', 'ivan_hanigan', 'ewedb',
                 schema = 'awap_grids', table = 'tmax2013010820130108',
                 p = 'kazoowazoo')
  # bah
  r <-
                 readGDAL("PG:host=115.146.84.135 port=5432 dbname='ewedb' user='ivan_hanigan' password='kazoowazoo' schema='awap_grids' table=tmax2013010820130108")
  
  r2 <- raster(r)
  r3 <- aggregate(r2, fact=2, fun = mean)
  writeGDAL(r2, 'data/test1.TIF',drivername="GTiff")
  writeRaster(r3, 'data/test2.TIF',format="GTiff")
  
                                          #writeGDAL(r3, "PG:host=115.146.84.135 port=5432 dbname='ewedb' user='ivan_hanigan' password='kazoowazoo' schema='awap_grids' table=tmax20130108201301082")
# gdalinfo  "PG:host=115.146.84.135 port=5432 dbname='ewedb' user='ivan_hanigan' password='kazoowazoo' schema='awap_grids' table=tmax2013010820130108"   
#+end_src

** test uncompress
#+name:test-uncompress
#+begin_src R :session *R* :tangle src/test-uncompress.r :exports none :eval no
################################################################
# name:test-uncompress
#http://cran.r-project.org/src/contrib/Archive/uncompress/uncompress_1.34.tar.gz
install.packages("C:/Users/Ivan/Downloads/uncompress_1.34.tar.gz", repos = NULL, type = "source")
require(uncompress)
?uncompress


files <- dir(pattern='.grid.Z')
strt=Sys.time()
for (f in files) {
   f <- files[1]
  print(f)
  handle <- file(f, "rb")
  data <- readBin(handle, "raw", 99999999)
  close(handle)
  uncomp_data <- uncompress(data)
  handle <- file(gsub('.Z','',f), "wb")
  writeBin(uncomp_data, handle)
  close(handle)
  
  # clean up
  #file.remove(f)
}

endd=Sys.time()
print(endd-strt)

sink('test.bat')
cat("\"C:\\pgutils\\postgis-pg92-binaries-2.0.2w64\\bin\\raster2pgsql\" -s 4283 -I -C -M *.grid -F awap_grids.maxave_aggby3 > maxave_aggby3.sql")
sink()
system('test.bat')
#+end_src

** move from rawdata (or 5 year chunks) to one year Directories
#+name:file-rename-to-annual
#+begin_src R :session *shell* :tangle no :exports none :eval no
  ################################################################
  # name:file-rename-to-annual
  require(ProjectTemplate)
  load.project()
  
  files <- dir('RawData', full.names = T, recursive = TRUE)
  files[1:20]
  for(v in vars[[1]]){
  #  v <- vars[[1]][2]
  vfiles <- files[grep(v, files)]
  for(fname in vfiles){
  #  fname <- vfiles[1]
    year <- substr(strsplit(fname,'_')[[1]][2],1,4)
    variablename <- strsplit(strsplit(fname,'_')[[1]][1],'/')[[1]][2]
    try(dir.create(file.path('data',variablename, year), recursive =
                   TRUE))
    outfile <- file.path('data',variablename, year, strsplit(fname,'/')[[1]][3])
    file.rename(fname, outfile)
  }
  }
  
#+end_src

** clean
#+name:clean
#+begin_src R :session *shell* :tangle src/clean.r :exports none :eval no
  ################################################################
  # name:clean
  # Project: AWAP_GRIDS
  # Author: ivanhanigan
  # Maintainer: Who to complain to <ivan.hanigan@gmail.com>
  require(ProjectTemplate)
  load.project()
  
  # All the potentially messy data cleanup
    ch <- connect2postgres(h = '115.146.84.135', db = 'ewedb', user= 'ivan_hanigan')
    # enter password at console
    shp <- dbGetQuery(ch, 'select stnum, lat, lon from weather_bom.combstats')
  #  shp <- dbGetQuery(ch, 'select sla_code, st_x(st_centroid(the_geom)) as lon, st_y(st_centroid(the_geom)) as lat from abs_sla.aussla01')
    nrow(shp)
    if (!require(rgdal)) install.packages('rgdal'); require(rgdal)
    epsg <- make_EPSG()
  
    ## Treat data frame as spatial points
    shp <- SpatialPointsDataFrame(cbind(shp$lon,shp$lat),shp,
                                  proj4string=CRS(epsg$prj4[epsg$code %in% '4283']))
    str(shp)
    head(shp@data)
    ## #writeOGR(shp, 'test.shp', 'test', driver='ESRI Shapefile')
  
  
    #################################
    # start getting CCD temperatures
    #setwd(rootdir)
  #  started <- Sys.time()
  #  for(v in 4:6){
     v = 1
    rootdir <- paste(getwd(),'/',variableslist[v,1],sep='')
  #  dir(rootdir)[1]
    cfiles <- dir(rootdir)
    cfiles <- cfiles[grep(as.character(variableslist[v,2]), cfiles)]
  
  #    for (i in seq_len(length(cfiles))) {# solar failed at this day 494:length(cfiles)){
      #   i <- 1
        #i <- grep('20000827',cfiles)
        fname <- cfiles[[i]]
        variablename <- strsplit(fname, '_')[[1]][1]
        timevar <- gsub('.TIF', '', strsplit(fname, '_')[[1]][2])
        timevar <- substr(timevar, 1,8)
        year <- substr(timevar, 1,4)
        month <- substr(timevar, 5,6)
        day <- substr(timevar, 7,8)
        timevar <- as.Date(paste(year, month, day, sep = '-'))
        r <- raster(file.path(rootdir,fname))
        e <- extract(r, shp, df=T)
        str(e) ## print for debugging
        image(r)
        plot(shp, add = T)
  
#+end_src

** do
#+name:do
#+begin_src R :session *R* :tangle src/do.r :exports none :eval no
################################################################
# name:do
# The actual work

#+end_src



** TODO zones
#+name:zones
#+begin_src R :session *R* :tangle src/zones.r :exports none :eval no
################################################################
# name:zones

#+end_src
* Conclusions
* versions
